confluent_platform_version: 4.1

######### Kafka Properties (/etc/kafka/server.properties) ########

############################# Server #############################

# The id of the broker. This must be set to a unique integer for each broker.
confluent_kafka_broker_id: 0

# The address the socket server listens on. It will get the value returned from
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = security_protocol://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092
confluent_kafka_listener_protocol: PLAINTEXT
confluent_kafka_listener_hostname: ''
confluent_kafka_listener_port: 9092

# Hostname and port the broker will advertise to producers and consumers. If not set,
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092
confluent_kafka_advertised_listener_protocol: PLAINTEXT
confluent_kafka_advertised_listener_hostname: '{{ inventory_hostname }}'
confluent_kafka_advertised_listener_port: 9092

# Enable auto creation of topic on the server
confluent_kafka_auto_create_topics_enable: false

# Enables delete topic. Delete topic through the admin tool will have no
# effect if this config is turned off
confluent_kafka_delete_topic_enable: true

# The number of threads handling network requests
confluent_kafka_num_network_threads: 3

# The number of threads doing disk I/O
confluent_kafka_num_io_threads: 8

############################# Log Basics #############################

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
confluent_kafka_num_recovery_threads_per_data_dir: 1

# A comma seperated list of directories under which to store log files
confluent_kafka_log_dirs: /var/lib/kafka

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
confluent_kafka_num_partitions: 1

# The minimum age of a log file to be eligible for deletion
confluent_kafka_log_retention_hours: 168

# Default replication factor for automatically created topics.
confluent_kafka_default_replication_factor: 1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
confluent_kafka_offsets_topic_replication_factor: 1
confluent_kafka_transaction_state_log_replication_factor: 1
confluent_kafka_transaction_state_log_min_isr: 1

############################# Log Retention Policy #############################

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
confluent_kafka_log_segment_bytes: 1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
confluent_kafka_log_retention_check_interval_ms: 300000


############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
confluent_kafka_zookeeper_connect: 'localhost:2181'

# Timeout in ms for connecting to zookeeper
confluent_kafka_zookeeper_connection_timeout: 6000


############################# Producer #############################

# list of brokers used for bootstrapping knowledge about the rest of the cluster
# format: host1:port1,host2:port2 ...
confluent_kafka_bootstrap_servers: 'localhost:9092'


##################### Confluent Proactive Support ######################

confluent_support_metrics_enable: false
confluent_support_customer_id: anonymous


#################### Connect Distributed ################################
# unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
confluent_connect_group_id: connect-cluster

confluent_connect_key_converter: org.apache.kafka.connect.json.JsonConverter
confluent_connect_value_converter: org.apache.kafka.connect.json.JsonConverter
confluent_connect_key_converter_schemas_enable: true
confluent_connect_value_converter_schemas_enable: true

confluent_connect_internal_key_converter: org.apache.kafka.connect.json.JsonConverter
confluent_connect_internal_value_converter: org.apache.kafka.connect.json.JsonConverter
confluent_connect_internal_key_converter_schemas_enable: false
confluent_connect_internal_value_converter_schemas_enable: false

confluent_connect_offset_storage_topic: connect-offsets
confluent_connect_offset_storage_replication_factor: 1
confluent_connect_offset_storage_partitions: 25

confluent_connect_config_storage_topic: connect-configs
confluent_connect_config_storage_replication_factor: 1

confluent_connect_status_storage_topic: connect-status
confluent_connect_status_storage_replication_factor: 1
confluent_connect_status_storage_partitions: 5

confluent_connect_offset_flush_interval_ms: 10000

confluent_connect_plugin_path: share/java

################### Connect Standalone ################################

confluent_connect_offset_storage_file_filename: /var/lib/kafka/connect.offsets


######### ZooKeeper Properties (/etc/kafka/zookeeper.properties) ########

# The directory where the snapshot is stored.
confluent_zookeeper_data_dir: '/var/lib/zookeeper'

# Directory to write the transaction log to the dataLogDir rather than the dataDir
# This allows a dedicated log device to be used, and helps avoid competition
confluent_zookeeper_data_log_dir: '/var/lib/zookeeper'

# The port at which the clients will connect
confluent_zookeeper_client_port: 2181

# Disable the per-ip limit on the number of connections since this is a non-production config
confluent_zookeeper_max_client_cnxns: 60

# Uniquely identifies the ZooKeeper instance when clustering ZooKeeper nodes.
# This value is placed in the /var/lib/zookeeper/myid file.
confluent_zookeeper_id: 1

confluent_zookeeper_leader_port: 2888
confluent_zookeeper_election_port: 3888


################ Schema Registry ############################

confluent_schema_registry_listener: PLAINTEXT://{{ inventory_hostname }}:9092
confluent_schema_registry_kafkastore_topic: _schemas
confluent_schema_registry_debug: false


################# REST Proxy ################################

confluent_rest_id: 1


################# KSQL ######################################

confluent_ksql_bootstrap_servers: localhost:9092
confluent_ksql_listeners: http://localhost:8088
confluent_ksql_server_ui_enabled: true
